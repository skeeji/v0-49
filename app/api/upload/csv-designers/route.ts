import { type NextRequest, NextResponse } from "next/server"
import clientPromise from "@/lib/mongodb"
import Papa from "papaparse"

const DBNAME = process.env.MONGO_INITDB_DATABASE || "luminaires"

export async function POST(request: NextRequest) {
  try {
    console.log("üë®‚Äçüé® API /api/upload/csv-designers - D√©but du traitement")

    const formData = await request.formData()
    const file = formData.get("file") as File

    if (!file) {
      return NextResponse.json({ error: "Aucun fichier fourni" }, { status: 400 })
    }

    console.log(`üìÅ Fichier CSV designers re√ßu: ${file.name} (${file.size} bytes)`)

    // Lire le contenu du fichier
    const text = await file.text()
    console.log(`üìä Contenu CSV: ${text.length} caract√®res`)

    // Parser le CSV avec Papa Parse
    const parseResult = Papa.parse(text, {
      header: true,
      skipEmptyLines: true,
      delimiter: ";", // Utiliser point-virgule comme d√©limiteur
      quoteChar: '"',
      escapeChar: '"',
      transformHeader: (header) => header.trim(),
    })

    if (parseResult.errors.length > 0) {
      console.log("‚ö†Ô∏è Erreurs de parsing:", parseResult.errors.slice(0, 5))
    }

    const data = parseResult.data as any[]
    console.log(`üìä ${data.length} lignes pars√©es`)

    if (data.length === 0) {
      return NextResponse.json({ error: "Aucune donn√©e trouv√©e dans le CSV" }, { status: 400 })
    }

    // Connexion √† MongoDB
    const client = await clientPromise
    const db = client.db(DBNAME)
    const collection = db.collection("designers")

    // Traitement par batch
    const BATCH_SIZE = 500
    let imported = 0
    const errors: string[] = []

    for (let i = 0; i < data.length; i += BATCH_SIZE) {
      const batch = data.slice(i, i + BATCH_SIZE)
      console.log(`üì¶ Traitement batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(data.length / BATCH_SIZE)}`)

      const designersToInsert = batch
        .map((row, index) => {
          try {
            return {
              nom: row.nom || row.Nom || "",
              biographie: row.biographie || row.Biographie || "",
              dateNaissance: row.dateNaissance || row.DateNaissance || "",
              dateDeces: row.dateDeces || row.DateDeces || "",
              nationalite: row.nationalite || row.Nationalite || "",
              imagedesigner: row.imagedesigner || row.ImageDesigner || "",
              createdAt: new Date(),
              updatedAt: new Date(),
            }
          } catch (error: any) {
            errors.push(`Ligne ${i + index + 1}: ${error.message}`)
            return null
          }
        })
        .filter(Boolean)

      if (designersToInsert.length > 0) {
        try {
          await collection.insertMany(designersToInsert)
          imported += designersToInsert.length
          console.log(`‚úÖ Batch ins√©r√©: ${designersToInsert.length} designers`)
        } catch (error: any) {
          console.error(`‚ùå Erreur insertion batch:`, error)
          errors.push(`Batch ${Math.floor(i / BATCH_SIZE) + 1}: ${error.message}`)
        }
      }
    }

    console.log(`‚úÖ Import termin√©: ${imported} designers import√©s`)

    return NextResponse.json({
      success: true,
      message: `Import termin√©: ${imported} designers import√©s sur ${data.length} lignes trait√©es`,
      imported,
      processed: data.length,
      errors: errors.slice(0, 10),
      totalErrors: errors.length,
    })
  } catch (error: any) {
    console.error("‚ùå Erreur critique lors de l'import designers:", error)
    return NextResponse.json(
      {
        success: false,
        error: "Erreur serveur lors de l'import des designers",
        details: error.message,
      },
      { status: 500 },
    )
  }
}
